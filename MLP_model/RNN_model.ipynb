{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_Crawling__Selenium.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimGriezmann/DeepLearning_BeTheLegend/blob/master/MLP_model/RNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZUvTKix_Wr"
      },
      "source": [
        "# **2018-21시즌 데이터를 사용한 MLP model**\n",
        "### Number of data = *29395*\n",
        "선발 출전한 선수\\\n",
        "3월, 4월 데이터 제외\\\n",
        "0타수인 데이터 제외\\\n",
        "avLI, RE24, WPA feature 추가\\\n",
        "Validation data set 추가\\\n",
        "loss & acc graph\n",
        "### Number of feature = *13*\n",
        "\n",
        "1. avg (타율)\n",
        "2. slg (장타율)\n",
        "3. ops (출루율 + 장타율)\n",
        "4. home/away_avg_y (홈/원정 별 타율)\n",
        "5. avLI\n",
        "6. RE24\n",
        "7. WPA\n",
        "8. vs_avg (상대 팀 타율)\n",
        "9. recent_5days_avg (최근 5일 타율)\n",
        "10. recent_5games_avg (최근 5경기 타율)\n",
        "11. recent_10games_avg (최근 10경기 타율)\n",
        "12. success_10days (최근 10일 성공률)\n",
        "13. success_10games (최근 10경기 성공률)\n",
        "\n",
        "acc = 0.8127\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9FtxTkzzZZr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVHrSFQLl3T9",
        "outputId": "46960c9f-cef8-45bb-f708-e25e7110dd1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpXdABfSmZEW",
        "outputId": "27677ba3-ddd8-481e-a997-7b957fba32bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5DR_EdFsRmq"
      },
      "source": [
        "final_2018_2021 = pd.read_csv('/content/drive/MyDrive/bethelegend/final_2018_2021.csv', encoding='euc-kr')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "p_UIY1Ntsr8f",
        "outputId": "03474579-e86a-47b4-c4f2-170a70907ca1"
      },
      "source": [
        "final_2018_2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>day</th>\n",
              "      <th>vs</th>\n",
              "      <th>result_x</th>\n",
              "      <th>bat_order</th>\n",
              "      <th>position</th>\n",
              "      <th>start_member</th>\n",
              "      <th>ab</th>\n",
              "      <th>score</th>\n",
              "      <th>hit</th>\n",
              "      <th>2_hit</th>\n",
              "      <th>3_hit</th>\n",
              "      <th>homerun</th>\n",
              "      <th>tb</th>\n",
              "      <th>rbi</th>\n",
              "      <th>sb</th>\n",
              "      <th>cs</th>\n",
              "      <th>bb</th>\n",
              "      <th>hpp</th>\n",
              "      <th>ibb</th>\n",
              "      <th>so</th>\n",
              "      <th>gdp</th>\n",
              "      <th>sh</th>\n",
              "      <th>sf</th>\n",
              "      <th>avg</th>\n",
              "      <th>obp</th>\n",
              "      <th>slg</th>\n",
              "      <th>ops</th>\n",
              "      <th>pitch</th>\n",
              "      <th>avLI</th>\n",
              "      <th>RE24</th>\n",
              "      <th>WPA</th>\n",
              "      <th>double</th>\n",
              "      <th>vs_team_x</th>\n",
              "      <th>home/away_x</th>\n",
              "      <th>home_ab_x</th>\n",
              "      <th>home_hit_x</th>\n",
              "      <th>away_ab_x</th>\n",
              "      <th>away_hit_x</th>\n",
              "      <th>home/away_avg_x</th>\n",
              "      <th>vs_team_y</th>\n",
              "      <th>home/away_y</th>\n",
              "      <th>home_ab_y</th>\n",
              "      <th>home_hit_y</th>\n",
              "      <th>away_ab_y</th>\n",
              "      <th>away_hit_y</th>\n",
              "      <th>home/away_avg_y</th>\n",
              "      <th>vs_team</th>\n",
              "      <th>result_y</th>\n",
              "      <th>home/away</th>\n",
              "      <th>vs_ab</th>\n",
              "      <th>vs_hit</th>\n",
              "      <th>vs_avg</th>\n",
              "      <th>recent_5days_avg</th>\n",
              "      <th>recent_5games_avg</th>\n",
              "      <th>recent_10games_avg</th>\n",
              "      <th>success_10days</th>\n",
              "      <th>success_10games</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>강백호</td>\n",
              "      <td>404</td>\n",
              "      <td>한화</td>\n",
              "      <td>W 3:2</td>\n",
              "      <td>4</td>\n",
              "      <td>1B</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.667</td>\n",
              "      <td>1.417</td>\n",
              "      <td>16</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>한화</td>\n",
              "      <td>home</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>한화</td>\n",
              "      <td>home</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>한화</td>\n",
              "      <td>1</td>\n",
              "      <td>home</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>강백호</td>\n",
              "      <td>406</td>\n",
              "      <td>LG</td>\n",
              "      <td>L 2:3</td>\n",
              "      <td>4</td>\n",
              "      <td>1B</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.661</td>\n",
              "      <td>14</td>\n",
              "      <td>2.07</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>LG</td>\n",
              "      <td>home</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>LG</td>\n",
              "      <td>home</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>LG</td>\n",
              "      <td>0</td>\n",
              "      <td>home</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>강백호</td>\n",
              "      <td>407</td>\n",
              "      <td>LG</td>\n",
              "      <td>W 7:3</td>\n",
              "      <td>4</td>\n",
              "      <td>1B</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.993</td>\n",
              "      <td>17</td>\n",
              "      <td>1.43</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>LG</td>\n",
              "      <td>home</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>LG</td>\n",
              "      <td>home</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>LG</td>\n",
              "      <td>1</td>\n",
              "      <td>home</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>강백호</td>\n",
              "      <td>408</td>\n",
              "      <td>LG</td>\n",
              "      <td>L 3:7</td>\n",
              "      <td>4</td>\n",
              "      <td>1B</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.467</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.467</td>\n",
              "      <td>0.996</td>\n",
              "      <td>17</td>\n",
              "      <td>0.89</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-0.102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>LG</td>\n",
              "      <td>home</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455</td>\n",
              "      <td>LG</td>\n",
              "      <td>home</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455</td>\n",
              "      <td>LG</td>\n",
              "      <td>1</td>\n",
              "      <td>home</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>강백호</td>\n",
              "      <td>409</td>\n",
              "      <td>@삼성</td>\n",
              "      <td>L 5:7</td>\n",
              "      <td>4</td>\n",
              "      <td>1B</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.600</td>\n",
              "      <td>1.145</td>\n",
              "      <td>21</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.88</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>삼성</td>\n",
              "      <td>away</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>삼성</td>\n",
              "      <td>away</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>삼성</td>\n",
              "      <td>1</td>\n",
              "      <td>away</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39113</th>\n",
              "      <td>강경학</td>\n",
              "      <td>1006</td>\n",
              "      <td>@롯데</td>\n",
              "      <td>L 5:8</td>\n",
              "      <td>9</td>\n",
              "      <td>PH</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.277</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.775</td>\n",
              "      <td>6</td>\n",
              "      <td>0.39</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>0.0</td>\n",
              "      <td>롯데</td>\n",
              "      <td>away</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>108</td>\n",
              "      <td>32</td>\n",
              "      <td>0.296</td>\n",
              "      <td>롯데</td>\n",
              "      <td>away</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>108</td>\n",
              "      <td>32</td>\n",
              "      <td>0.296</td>\n",
              "      <td>롯데</td>\n",
              "      <td>0</td>\n",
              "      <td>away</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39114</th>\n",
              "      <td>강경학</td>\n",
              "      <td>1009</td>\n",
              "      <td>@KT</td>\n",
              "      <td>W 10:6</td>\n",
              "      <td>8</td>\n",
              "      <td>PH</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.278</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.774</td>\n",
              "      <td>15</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>KT</td>\n",
              "      <td>away</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>109</td>\n",
              "      <td>32</td>\n",
              "      <td>0.294</td>\n",
              "      <td>KT</td>\n",
              "      <td>away</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>109</td>\n",
              "      <td>32</td>\n",
              "      <td>0.294</td>\n",
              "      <td>KT</td>\n",
              "      <td>1</td>\n",
              "      <td>away</td>\n",
              "      <td>36</td>\n",
              "      <td>12</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39115</th>\n",
              "      <td>강경학</td>\n",
              "      <td>1019</td>\n",
              "      <td>넥센</td>\n",
              "      <td>L 2:3</td>\n",
              "      <td>9</td>\n",
              "      <td>PR</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>넥센</td>\n",
              "      <td>home</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>112</td>\n",
              "      <td>33</td>\n",
              "      <td>0.263</td>\n",
              "      <td>넥센</td>\n",
              "      <td>home</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>112</td>\n",
              "      <td>33</td>\n",
              "      <td>0.263</td>\n",
              "      <td>넥센</td>\n",
              "      <td>0</td>\n",
              "      <td>home</td>\n",
              "      <td>27</td>\n",
              "      <td>8</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39116</th>\n",
              "      <td>강경학</td>\n",
              "      <td>1020</td>\n",
              "      <td>넥센</td>\n",
              "      <td>L 5:7</td>\n",
              "      <td>7</td>\n",
              "      <td>PH</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6</td>\n",
              "      <td>1.94</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>0.0</td>\n",
              "      <td>넥센</td>\n",
              "      <td>home</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>112</td>\n",
              "      <td>33</td>\n",
              "      <td>0.263</td>\n",
              "      <td>넥센</td>\n",
              "      <td>home</td>\n",
              "      <td>133</td>\n",
              "      <td>35</td>\n",
              "      <td>112</td>\n",
              "      <td>33</td>\n",
              "      <td>0.263</td>\n",
              "      <td>넥센</td>\n",
              "      <td>0</td>\n",
              "      <td>home</td>\n",
              "      <td>27</td>\n",
              "      <td>8</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39117</th>\n",
              "      <td>강경학</td>\n",
              "      <td>1023</td>\n",
              "      <td>@넥센</td>\n",
              "      <td>L 2:5</td>\n",
              "      <td>8</td>\n",
              "      <td>PH</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.500</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.0</td>\n",
              "      <td>넥센</td>\n",
              "      <td>away</td>\n",
              "      <td>134</td>\n",
              "      <td>35</td>\n",
              "      <td>112</td>\n",
              "      <td>33</td>\n",
              "      <td>0.295</td>\n",
              "      <td>넥센</td>\n",
              "      <td>away</td>\n",
              "      <td>134</td>\n",
              "      <td>35</td>\n",
              "      <td>112</td>\n",
              "      <td>33</td>\n",
              "      <td>0.295</td>\n",
              "      <td>넥센</td>\n",
              "      <td>1</td>\n",
              "      <td>away</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39118 rows × 58 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      name   day   vs  ... recent_10games_avg  success_10days success_10games\n",
              "0      강백호   404   한화  ...           0.000000        0.000000        0.000000\n",
              "1      강백호   406   LG  ...           0.666667        1.000000        1.000000\n",
              "2      강백호   407   LG  ...           0.285714        0.500000        0.500000\n",
              "3      강백호   408   LG  ...           0.454545        0.666667        0.666667\n",
              "4      강백호   409  @삼성  ...           0.466667        0.750000        0.750000\n",
              "...    ...   ...  ...  ...                ...             ...             ...\n",
              "39113  강경학  1006  @롯데  ...           0.200000        0.500000        0.400000\n",
              "39114  강경학  1009  @KT  ...           0.222222        0.333333        0.400000\n",
              "39115  강경학  1019   넥센  ...           0.235294        1.000000        0.400000\n",
              "39116  강경학  1020   넥센  ...           0.235294        0.000000        0.400000\n",
              "39117  강경학  1023  @넥센  ...           0.176471        0.000000        0.300000\n",
              "\n",
              "[39118 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "DLA515YOszeW",
        "outputId": "7f312838-66c6-4858-a88d-8d1fbcf6ba48"
      },
      "source": [
        "sns.countplot(final_2018_2021['ab'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1f36nesIrz"
      },
      "source": [
        "#선발 출장에 한정\n",
        "final_2018_2021 = final_2018_2021[final_2018_2021['start_member'] == 1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sup1IOqbwfFr"
      },
      "source": [
        "#3월, 4월 데이터 제외\n",
        "final_2018_2021 = final_2018_2021.loc[final_2018_2021['day']>= 500]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4wzQ2cX2Ue"
      },
      "source": [
        "#0타수 데이터 제외\n",
        "final_2018_2021 = final_2018_2021[final_2018_2021['ab']>0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZZyPZ6MXTai"
      },
      "source": [
        "final_2018_2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vKbGIXYnVOa"
      },
      "source": [
        "### **Multi layer Perceptron in Be the legend**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFweHbLdmuMq"
      },
      "source": [
        "mlp_data = final_2018_2021.loc[:, ['name', 'day', 'start_member', 'vs_team', 'avg', 'slg', 'ops', 'avLI', 'RE24', 'WPA', 'home/away_avg_y', 'vs_ab', 'vs_hit', 'vs_avg', 'recent_5days_avg', 'recent_5games_avg', 'recent_10games_avg', 'success_10days', 'success_10games', 'result_y']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNns44d1muU0"
      },
      "source": [
        "mlp_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cid426-ZUot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1010b17d-1852-40d1-f3e0-dc5bdd9202ed"
      },
      "source": [
        "len(mlp_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29395"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnGxy06A1Yos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2a0398-b138-4577-f519-ea42f1005cb7"
      },
      "source": [
        "len(mlp_data[mlp_data['result_y'] == 1]) / len(mlp_data) * 100"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.47065827521688"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iD5efWEmuXc"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj57pdhG-Dgk"
      },
      "source": [
        "### **Training data set / Test data set 분할**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7_-up_YmuZa"
      },
      "source": [
        "mlp_train, mlp_test = train_test_split(mlp_data, test_size=0.3, random_state=50)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYFYC0nSuAxq"
      },
      "source": [
        "#현재 가지고 있는 모든 피쳐 사용\n",
        "\n",
        "X_train = mlp_train.loc[:, ['avg', 'slg', 'ops', 'avLI', 'RE24', 'WPA', 'home/away_avg_y', 'vs_avg', 'recent_5days_avg', 'recent_5games_avg', 'recent_10games_avg', 'success_10days', 'success_10games']]\n",
        "y_train = mlp_train.loc[:, ['result_y']]\n",
        "\n",
        "X_test = mlp_test.loc[:, ['avg', 'slg', 'ops', 'avLI', 'RE24', 'WPA', 'home/away_avg_y', 'vs_avg', 'recent_5days_avg', 'recent_5games_avg', 'recent_10games_avg', 'success_10days', 'success_10games']]\n",
        "y_test = mlp_test.loc[:, ['result_y']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcVedMqPpAkB"
      },
      "source": [
        "X_train = X_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEiz1UpqpCgQ"
      },
      "source": [
        "number_of_train_samples = X_train.shape[0]\n",
        "width = X_train.shape[1]\n",
        "X_train = X_train.reshape(number_of_train_samples, width)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xow9qw6IpFuY"
      },
      "source": [
        "number_of_test_samples = X_test.shape[0]\n",
        "X_test = X_test.reshape(number_of_test_samples, width)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Vnpzu_pHnB"
      },
      "source": [
        "X_train = minmax_scale(X_train, feature_range=(0,1), axis = 0)\n",
        "X_test = minmax_scale(X_test, feature_range=(0,1), axis = 0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C94ziVRUpMlw"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaF_pitWR328"
      },
      "source": [
        "### **Stratified K-Fold Cross Validation (auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz1cP4peWSfE"
      },
      "source": [
        "mlp_data = final_2018_2021.loc[:, ['name', 'day', 'start_member', 'vs_team', 'avg', 'slg', 'ops', 'avLI', 'RE24', 'WPA', 'home/away_avg_y', 'vs_ab', 'vs_hit', 'vs_avg', 'recent_5days_avg', 'recent_5games_avg', 'recent_10games_avg', 'success_10days', 'success_10games', 'result_y']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oco65SmER-oa"
      },
      "source": [
        "X = mlp_data.loc[:, ['avg', 'slg', 'ops', 'avLI', 'RE24', 'WPA', 'home/away_avg_y', 'vs_avg', 'recent_5days_avg', 'recent_5games_avg', 'recent_10games_avg', 'success_10days', 'success_10games']]\n",
        "y = mlp_data.loc[:, ['result_y']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWCFzXFxhDJR"
      },
      "source": [
        "X = mlp_data.loc[:, ['avg', 'slg', 'ops', 'home/away_avg_y', 'vs_avg', 'recent_5days_avg', 'recent_5games_avg', 'recent_10games_avg', 'success_10days', 'success_10games']]\n",
        "y = mlp_data.loc[:, ['result_y']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEw6LFG_R-qW"
      },
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFU4j55cUxeG"
      },
      "source": [
        "number_of_samples = X.shape[0]\n",
        "width = X.shape[1]\n",
        "X = X.reshape(number_of_samples, width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6vwp0LJUxgm"
      },
      "source": [
        "X = minmax_scale(X, feature_range=(0,1), axis = 0)\n",
        "y = to_categorical(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDyX-Z8KUxiv"
      },
      "source": [
        "def mlp_model_k():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJy-__-UxoS"
      },
      "source": [
        "model = KerasClassifier(build_fn=mlp_model_k, epochs=150, batch_size=32, verbose=0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c88NlgkVgoU"
      },
      "source": [
        " kfold = KFold(n_splits = 5, shuffle = True, random_state = 50) \n",
        " results = cross_val_score(model, X, y, cv=kfold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7chLlKGu4aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08de77b-be5e-46d3-fc53-2c73dce3326b"
      },
      "source": [
        "results, round(np.mean(results),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.68293929, 0.69773769, 0.68634123, 0.68532062, 0.687702  ]), 0.688)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TktpLH5w-KCz"
      },
      "source": [
        "### **Validation data set / Training data set 분할**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV0xUno7-YWb"
      },
      "source": [
        "X_val = X_train[:5000]\n",
        "X_train = X_train[5000:]\n",
        "\n",
        "y_val = y_train[:5000]\n",
        "y_train = y_train[5000:]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHEdmEEopvT"
      },
      "source": [
        "### **MLP experiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JQxtEOZot6K"
      },
      "source": [
        "# MLP model_1\n",
        "# 3 layers & 64 units\n",
        "# activation = sigmoid & softmax\n",
        "# loss = binary_crossentrophy, optimizer = rmsprop\n",
        "# loss: 0.4028 & acc: 0.8135\n",
        "\n",
        "def mlp_model1():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, activation = 'sigmoid'))\n",
        "    model.add(Dense(64, activation = 'sigmoid'))\n",
        "    model.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4s24meEot-y",
        "outputId": "7d93121e-855f-4a55-b49c-fe4361ab1b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "model1 = mlp_model1()\n",
        "history = model1.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b50d9a6141fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40GQE1sTtsS0"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_WfNztgvNn7"
      },
      "source": [
        "results = model1.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqLA82YOxAp6"
      },
      "source": [
        "# MLP model_2\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = rmsprop\n",
        "# loss: 0.4365 & acc: 0.8042\n",
        "\n",
        "def mlp_model2():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, activation = 'relu'))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dense(2, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ESFDrhrxAsQ"
      },
      "source": [
        "model2 = mlp_model2()\n",
        "history = model2.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU5YwJflxAuS"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB91YnrAyphm"
      },
      "source": [
        "results = model2.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbl3uNcQzymb"
      },
      "source": [
        "# MLP model_3\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = rmsprop\n",
        "# initialization = kernel_initializer\n",
        "# loss: 0.4474 & acc: 0.8026\n",
        "\n",
        "def mlp_model3():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'glorot_uniform'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(64, kernel_initializer = 'glorot_uniform'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(2, kernel_initializer = 'glorot_uniform'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szM9_oFbzyoq"
      },
      "source": [
        "model3 = mlp_model3()\n",
        "history = model3.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gByGO68rzyrA"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_9QnyIDzytB"
      },
      "source": [
        "results = model3.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TgMx7bDzyvH"
      },
      "source": [
        "# MLP model_4\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = rmsprop\n",
        "# initialization = HeNormal\n",
        "# loss: 0.4607 & acc: 0.7965\n",
        "\n",
        "def mlp_model4():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrMy0rt1zy61"
      },
      "source": [
        "model4 = mlp_model4()\n",
        "history = model4.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDiZrsoB3UFl"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFL8yPVc3UH8"
      },
      "source": [
        "results = model4.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl0CNe4_3UKJ"
      },
      "source": [
        "# MLP model_5\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = adam\n",
        "# initialization = HeNormal\n",
        "# loss: 0.4173 & acc: 0.8132\n",
        "\n",
        "def mlp_model5():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0_4U_mn3gS0"
      },
      "source": [
        "model5 = mlp_model5()\n",
        "history = model5.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCskPa6i3gVK"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8HEcP793gXl"
      },
      "source": [
        "results = model5.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ7LL8kz5_zO"
      },
      "source": [
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtvO37v73gZV"
      },
      "source": [
        "# MLP model_6 \n",
        "# Batch_Normal\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = adam\n",
        "# initialization = HeNormal\n",
        "# loss: 0.6793 & acc: 0.7383\n",
        "\n",
        "def mlp_model6():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDCWOR4m4cpV"
      },
      "source": [
        "model6 = mlp_model6()\n",
        "history = model6.fit(X_train, y_train, epochs = 200, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcVDeTg74cr2"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywhxuTTR4cuD"
      },
      "source": [
        "results = model6.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbC8a58R8Jfd"
      },
      "source": [
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkDLxg088JiC"
      },
      "source": [
        "# MLP model_7 \n",
        "# Dropout\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = adam\n",
        "# initialization = HeNormal\n",
        "# loss: 0.4284 - acc: 0.7910\n",
        "\n",
        "def mlp_model7():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nM0Oewe8JkR"
      },
      "source": [
        "model7 = mlp_model7()\n",
        "history = model7.fit(X_train, y_train, epochs = 200, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr4ycuFD8JmF"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9enddAl83hz"
      },
      "source": [
        "results = model7.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgJLV5pR-X7U"
      },
      "source": [
        "# MLP model_8\n",
        "# Batch_Normal\n",
        "# Dropout\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = adam\n",
        "# initialization = HeNormal\n",
        "# loss: 0.5285 - acc: 0.7452\n",
        "\n",
        "def mlp_model8():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTauP1WDBIIE"
      },
      "source": [
        "model8 = mlp_model8()\n",
        "history = model8.fit(X_train, y_train, epochs = 200, validation_data=(X_val, y_val), verbose = 0)\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6augmglNBILQ"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_u8U2djBcDE"
      },
      "source": [
        "results = model8.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9LOSAKHD08n"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB6jU0-IDd5l"
      },
      "source": [
        "# MLP model_ensemble\n",
        "# Dropout\n",
        "# 3 layers & 64 units\n",
        "# activation = relu & sigmoid\n",
        "# loss = binary_crossentrophy, optimizer = adam\n",
        "# initialization = HeNormal\n",
        "# loss: 0.5285 - acc: 0.7452\n",
        "\n",
        "def mlp_model_en():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(64, input_dim= width, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(64, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(2, kernel_initializer = 'HeNormal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkEwz6KQDd7t"
      },
      "source": [
        "en_model1 = KerasClassifier(build_fn = mlp_model_en, epochs = 200, verbose = 0)\n",
        "en_model1._estimator_type=\"classifier\"\n",
        "en_model2 = KerasClassifier(build_fn = mlp_model_en, epochs = 200, verbose = 0)\n",
        "en_model2._estimator_type=\"classifier\"\n",
        "en_model3 = KerasClassifier(build_fn = mlp_model_en, epochs = 200, verbose = 0)\n",
        "en_model3._estimator_type=\"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGbb5rPRF4kk"
      },
      "source": [
        "y_train = np.argmax(y_train, axis = 1)\n",
        "y_test = np.argmax(y_test, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKCfOUT-Dd-A"
      },
      "source": [
        "ensemble_clf = VotingClassifier(estimators = [('en_model1', en_model1), ('en_model2', en_model2), ('en_model3', en_model3)], voting = 'soft')\n",
        "ensemble_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-xIcJTwDeAJ"
      },
      "source": [
        "y_pred = ensemble_clf.predict(X_test)\n",
        "print('Acc: ', accuracy_score(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO4sL2DHmDwB"
      },
      "source": [
        "### **SimpleRNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYqmiQIqmJZC"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Activation\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdzVZUbTmQh1"
      },
      "source": [
        "def simple_rnn():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(SimpleRNN(50, input_shape = (width,1), return_sequences = False))\n",
        "    model.add(Dense(20))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    \n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['acc'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFBbq1JPnSUf",
        "outputId": "dad2401a-0855-4dfd-955f-96b96118f513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "model = KerasClassifier(build_fn = simple_rnn, epochs = 200, batch_size = 50, verbose = 1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_ = np.argmax(y_test, axis = 1)\n",
        "print(accuracy_score(y_pred, y_test_))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-461502092619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:218 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1msZcVCmf8-"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'red', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'green', label='Validation loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc, 'red', label='Training acc') \n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3zCrWWZmmXG"
      },
      "source": [
        "results = model1.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}